we present a new method for discriminatively weighting out - of - domain phrase pairs according to their relevance to the target domain , determined by both how similar to it they appear to be , and whether they belong to general language or not .  this extends previous work on discriminative weighting by using a finer granularity , focusing on the properties of instances rather than corpus components , and using a simpler training procedure .  we find that instance weighting yields consistent improvements over a wide range of baselines . even when there is training data available in the domain of interest , there is often additional data from other domains that could in principle be used to improve performance. the natural baseline approach is to concatenate data from in and out.even when there is training data available in the domain of interest , there is often additional data from other domains that could in principle be used to improve performance. in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in ) .